var documenterSearchIndex = {"docs":
[{"location":"writers/#Saving-the-diagnostics","page":"Saving output","title":"Saving the diagnostics","text":"Writers are needed to save the computed diagnostics.\n\nClimaDiagnostics comes with three writers:\n\nNetCDFWriter, to interpolate and save to NetCDF files;\nDictWriter, to save Fields to dictionaries in memory;\nHDF5Writer, to save Fields to HDF5 files.\n\n(There is an additional DummyWriter that does nothing. It is mostly used internally for testing and debugging.)\n\nUsers are welcome to implement their own writers. A writer has to be a subtype of AbstractWriterand has to implement the interpolate_field! and write_field! methods. interpolate_field! can return nothing is no interpolation is needed.","category":"section"},{"location":"writers/#NetCDFWriter","page":"Saving output","title":"NetCDFWriter","text":"The NetCDFWriter resamples the input Field to a rectangular grid and saves the output to a NetCDF file.\n\nThe NetCDFWriter relies on the Remappers module in ClimaCore to interpolate onto the rectangular grid. Horizontally, this interpolation is a Lagrange interpolation, vertically, it is a linear. This interpolation is not conservative. Also note that, the order of vertical interpolation drops to zero in the first and last vertical elements of each column.\n\nTo create a NetCDFWriter, you need to specify the source ClimaCore Space and the output directory where the files should be saved. By default, the NetCDFWriter appends to existing files and create new ones if they do not exist. The NetCDFWriter does not overwrite existing data and will error out if existing data is inconsistent with the new one.\n\nOptionally (recommended), you can pass an optional argument start_date, which will be saved as an attribute of your NetCDF file, easily accessible.\n\nNetCDFWriters take as one of the inputs the desired number of points along each of the dimensions. For the horizontal dimensions, points are sampled linearly. For the vertical dimension, the behavior can be customized by passing the z_sampling_method variable. When z_sampling_method = ClimaDiagnostics.Writers.LevelMethod(), points evaluated on the grid levels (and the provided number of points ignored), when z_sampling_method = ClimaDiagnostics.Writers.FakePressureLevelsMethod(), points are sampled uniformly in simplified hydrostatic atmospheric model.\n\nThe output in the NetCDFWriter roughly follows the CF conventions.\n\nEach ScheduledDiagnostic is output to a different file with name determined by calling the output_short_name on the ScheduledDiagnostic. Typically, these files have names like ta_1d_max.nc, ha_20s_inst.nc, et cetera. The files define their dimensions (lon, lat, z, ...). Time is always the first dimension is any dataset.\n\nDo not forget to close your writers to avoid file corruption!\n\nTo help reducing data loss, NetCDFWriter can force syncing, i.e. flushing the values to disk. Usually, NetCDF buffers writes to disk (because they are expensive), meaning values are not immediately written but are saved to disk in batch. This can result in data loss, and it is often useful to force NetCDF to write to disk (this is especially the case when working with GPUs). To do so, you can pass the sync_schedule function to the constructor of NetCDFWriter. When not nothing, sync_schedule is a callable that takes one argument (the integrator) and returns a bool. When the bool is true, the files that were modified since the last sync will be synced. For example, to force sync every 1000 steps, you can pass the ClimaDiagnostics.Schedules.DivisorSchedule(1000) schedule. By default, on GPUs, we call sync at the end of every time step for those files that need to be synced.\n\nVariables are saved as datasets with attributes, where the attributes include long_name, standard_name, units...\n\nGlobal attributes can be added to the NetCDF files via the global_attribs keyword argument for the NetCDFWriter. For example, you may want to specify the source and experiment attributes, which are the same across all NetCDF files produced for a single simulation.\n\nwriter = NetCDFWriter(\n    space, # 2D space with longitudes and latitudes\n    output_dir;\n    global_attribs = Dict(\"source\" => \"CliMA Coupler Simulation\", \"experiment\" => \"AMIP\"),\n)\n\nThe global attributes must be a subtype of AbstractDict{String, String}. If the order of the attributes matters, you may want to use an OrderedDict from OrderedCollections.jl.\n\nnote: Note\nThe NetCDFWriter cannot save raw ClimaCore.Fields, only fields that are resampled onto a Cartesian grids are supported. If you need such capability, consider using the ClimaDiagnostics.Writers.HDF5Writer.\n\nSampling methods for the vertical direction:","category":"section"},{"location":"writers/#DictWriter","page":"Saving output","title":"DictWriter","text":"The DictWriter is a in-memory writer that is particularly useful for interactive work and debugging.","category":"section"},{"location":"writers/#HDF5Writer","page":"Saving output","title":"HDF5Writer","text":"The HDF5Writer writes the Field directly to an HDF5 file in such a way that it can be later read and imported using the InputOutput module in ClimaCore.\n\nThe HDF5Writer writes one file per variable per timestep. The name of the file is determined by the output_short_name field of the ScheduledDiagnostic that is being output.\n\nNote: The HDF5Writer in ClimaDiagnostics is currently the least developed one. If you need this writer, we can expand it.","category":"section"},{"location":"writers/#ClimaDiagnostics.Writers.NetCDFWriter-Tuple{ClimaCore.Spaces.AbstractSpace, Any}-writers","page":"Saving output","title":"ClimaDiagnostics.Writers.NetCDFWriter","text":"NetCDFWriter(space, output_dir)\n\nSave a ScheduledDiagnostic to a NetCDF file inside the output_dir of the simulation by performing a pointwise (non-conservative) remapping first.\n\nKeyword arguments\n\nspace: Space where the Fields are defined. This is the most general space across the          Fields. In general, this is a 3D space. From a 3D space, you can take slices and           write 2D Fields, but the opposite is not true.\noutput_dir: The base folder where the files should be saved.\nnum_points: How many points to use along the different dimensions to interpolate the               fields. This is a tuple of integers, typically having meaning Long-Lat-Z,               or X-Y-Z (the details depend on the configuration being simulated).\nz_sampling_method: Instance of a AbstractZSamplingMethod that determines how points                      on the vertical direction should be chosen. By default, the vertical                      points are sampled on the grid levels.\ncompression_level: How much to compress the output NetCDF file (0 is no compression, 9                      is maximum compression).\nsync_schedule: Schedule that determines when to call NetCDF.sync (to flush the output                  to disk). When NetCDF.sync is called, you can guarantee that the bits                  are written to disk (instead of being buffered in memory). A schedule is                  a boolean callable that takes as a single argument the integrator.                  sync_schedule can also be set as nothing, in which case we let                  handling buffered writes to disk.\nstart_date: Date of the beginning of the simulation.\nhorizontal_pts: A tuple of vectors of floats meaning Long-Lat or X-Y (the details depend on the configuration being simulated).\nglobal_attribs: Optional dictionary of global attributes to include in all NetCDF files produced by this NetCDFWriter. These attributes are useful for storing metadata such as source, creation_date, or frequency. Must be nothing or a subtype of AbstractDict{String, String}. Default is nothing.\n\n\n\n\n\n","category":"method"},{"location":"writers/#ClimaDiagnostics.Writers.interpolate_field!-Tuple{ClimaDiagnostics.Writers.NetCDFWriter, Vararg{Any, 5}}-writers","page":"Saving output","title":"ClimaDiagnostics.Writers.interpolate_field!","text":"interpolate_field!(writer::NetCDFWriter, field, diagnostic, u, p, t)\n\nPerform interpolation of field and save output in preallocated areas of writer.\n\n\n\n\n\n","category":"method"},{"location":"writers/#ClimaDiagnostics.Writers.write_field!-Tuple{ClimaDiagnostics.Writers.NetCDFWriter, Vararg{Any, 5}}-writers","page":"Saving output","title":"ClimaDiagnostics.Writers.write_field!","text":"write_field!(writer::NetCDFWriter, field::Fields.Field, diagnostic, u, p, t)\n\nSave the resampled field produced by diagnostic as directed by the writer.\n\nOnly the root process does something here.\n\nNote: It assumes that the field is already resampled.\n\nThe target file is determined by output_short_name(diagnostic). If the target file already exists, append to it. If not, create a new file. If the file does not contain dimensions, they are added the first time something is written.\n\nTime handling:\n\nFor reduced diagnostics: timestamps are stored at the START of the reduction period, with time_bnds showing [start, end] of the period. For the first write, t=0 is assumed; for subsequent writes, the end of the previous period is used.\nFor instantaneous diagnostics: timestamps are stored at the current time, with timebnds showing [previoustime, current_time].\n\nAttributes are appended to the dataset:\n\nshort_name\nlong_name\nunits\ncomments\nstart_date\n\n\n\n\n\n","category":"method"},{"location":"writers/#ClimaDiagnostics.Writers.sync-Tuple{ClimaDiagnostics.Writers.NetCDFWriter}-writers","page":"Saving output","title":"ClimaDiagnostics.Writers.sync","text":"sync(writer::NetCDFWriter)\n\nCall NCDatasets.sync on all the files in the writer.unsynced_datasets list. NCDatasets.sync ensures that the values are written to file.\n\n\n\n\n\n","category":"method"},{"location":"writers/#Base.close-Tuple{ClimaDiagnostics.Writers.NetCDFWriter}-writers","page":"Saving output","title":"Base.close","text":"close(writer::NetCDFWriter)\n\nClose all the open files in writer.\n\n\n\n\n\n","category":"method"},{"location":"writers/#ClimaDiagnostics.Writers.AbstractZSamplingMethod","page":"Saving output","title":"ClimaDiagnostics.Writers.AbstractZSamplingMethod","text":"AbstractZSamplingMethod\n\nThe AbstractZInterpolationMethod defines how points along the vertical axis should be sampled.\n\nIn other words, if a column is defined between 0 and 100 and the target number of points is 50, how should those 50 points be chosen?\n\nAvailable methods are:\n\nLevelMethod: just use the grid levels\nFakePressureLevelsMethod: linearly spaced in (very) approximate atmospheric pressure levels\n\n\n\n\n\n","category":"type"},{"location":"writers/#ClimaDiagnostics.Writers.LevelsMethod","page":"Saving output","title":"ClimaDiagnostics.Writers.LevelsMethod","text":"LevelsMethod\n\nDo not perform interpolation on z, use directly the grid levels instead.\n\n\n\n\n\n","category":"type"},{"location":"writers/#ClimaDiagnostics.Writers.FakePressureLevelsMethod","page":"Saving output","title":"ClimaDiagnostics.Writers.FakePressureLevelsMethod","text":"FakePressureLevelsMethod\n\nLinearly sample points from z_min to z_max in pressure levels assuming a very simplified hydrostatic balance model.\n\nPressure is approximated with\n\np ~ pâ‚€ exp(-z/H)\n\nH is assumed to be 7000 m, which is a good scale height for the Earth atmosphere.\n\n\n\n\n\n","category":"type"},{"location":"writers/#ClimaDiagnostics.Writers.DictWriter-Tuple{}","page":"Saving output","title":"ClimaDiagnostics.Writers.DictWriter","text":"DictWriter()\n\nA simple in-memory writer. Useful for interactive work and debugging.\n\nYou can retrieve values using the typical dictionary interface and using as keys the names of the stored diagnostics.\n\nExample\n\nAssuming we have a diagnostic with short output name \"mydiag\" stored in dictW. dictW[\"mydiag\"] will be a dictionary with keys the timesteps when the data was saved. The values are the diagnostic output (typically a ClimaCore Field).\n\n\n\n\n\n","category":"method"},{"location":"writers/#ClimaDiagnostics.Writers.write_field!-Tuple{ClimaDiagnostics.Writers.DictWriter, Vararg{Any, 5}}","page":"Saving output","title":"ClimaDiagnostics.Writers.write_field!","text":"write_field!(writer::DictWriter, field, diagnostic, u, p, t)\n\nAdd an entry to the writer at time t for the current diagnostic with value field.\n\nDictWriter is backed by a dictionary. Most typically, the keys of this dictionary are either strings, the output_short_name of the diagnostic. If the output_short_name is not available, use the diagnostic itself. The values of this dictionary is another dictionary that maps the time t to the field at that value.\n\nDictWriter implements a basic read-only dictionary interface to access the times and values.\n\n\n\n\n\n","category":"method"},{"location":"writers/#ClimaDiagnostics.Writers.HDF5Writer-writers","page":"Saving output","title":"ClimaDiagnostics.Writers.HDF5Writer","text":"HDF5Writer(output_dir)\n\nSave a ScheduledDiagnostic to a HDF5 file inside the output_dir.\n\nnote: Note\nThis writer is not very efficient, but it is currently the only writer that can save ClimaCore.Fields. Please, get in touch if you need this capability.\n\n\n\n\n\n","category":"type"},{"location":"writers/#ClimaDiagnostics.Writers.write_field!-Tuple{ClimaDiagnostics.Writers.HDF5Writer, Vararg{Any, 5}}-writers","page":"Saving output","title":"ClimaDiagnostics.Writers.write_field!","text":"write_field!(writer::HDF5Writer, field, diagnostic, u, p, t)\n\nSave a ScheduledDiagnostic to a HDF5 file inside the output_dir.\n\nThe name of the file is determined by the output_short_name of the output ScheduledDiagnostic. New files are created for each timestep.\n\nFields can be read back using the InputOutput module in ClimaCore.\n\n\n\n\n\n","category":"method"},{"location":"writers/#Base.close-Tuple{ClimaDiagnostics.Writers.HDF5Writer}-writers","page":"Saving output","title":"Base.close","text":"close(writer::HDF5Writer)\n\nClose all the files open in writer. (Currently no-op.)\n\n\n\n\n\n","category":"method"},{"location":"api/#Public-APIs","page":"APIs","title":"Public APIs","text":"","category":"section"},{"location":"api/#ClimaDiagnostics","page":"APIs","title":"ClimaDiagnostics","text":"","category":"section"},{"location":"api/#Schedules","page":"APIs","title":"Schedules","text":"","category":"section"},{"location":"api/#DiagnosticVariables","page":"APIs","title":"DiagnosticVariables","text":"","category":"section"},{"location":"api/#ScheduledDiagnostics","page":"APIs","title":"ScheduledDiagnostics","text":"","category":"section"},{"location":"api/#Writers","page":"APIs","title":"Writers","text":"","category":"section"},{"location":"api/#ClimaDiagnostics.DiagnosticsHandler","page":"APIs","title":"ClimaDiagnostics.DiagnosticsHandler","text":"DiagnosticsHandler\n\nA struct that contains the scheduled diagnostics, ancillary data and areas of memory needed to store and accumulate results.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.orchestrate_diagnostics","page":"APIs","title":"ClimaDiagnostics.orchestrate_diagnostics","text":"orchestrate_diagnostics(integrator, diagnostic_handler::DiagnosticsHandler)\n\nLoop over all the ScheduledDiagnostics in diagnostic_handler and run compute and output according to their schedule functions.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.DiagnosticsCallback","page":"APIs","title":"ClimaDiagnostics.DiagnosticsCallback","text":"DiagnosticsCallback(diagnostics_handler::DiagnosticsHandler)\n\nTranslate a DiagnosticsHandler into a SciML callback ready to be used.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.IntegratorWithDiagnostics","page":"APIs","title":"ClimaDiagnostics.IntegratorWithDiagnostics","text":"IntegratorWithDiagnostics(integrator,\n                          scheduled_diagnostics;\n                          state_name = :u,\n                          cache_name = :p)\n\nReturn a new integrator with diagnostics defined by scheduled_diagnostics.\n\nIntegratorWithDiagnostics is conceptually similar to defining a DiagnosticsHandler, constructing its associated DiagnosticsCallback, and adding such callback to a given integrator.\n\nThe new integrator is identical to the previous one with the only difference that it has a new callback called after all the other callbacks to accumulate/output diagnostics.\n\nIntegratorWithDiagnostics ensures that the diagnostic callbacks are initialized and called after everything else is initialized and computed.\n\nIntegratorWithDiagnostics assumes that the state is integrator.u and the cache is integrator.p. This behavior can be customized by passing the state_name and cache_name keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.Schedules.AbstractSchedule","page":"APIs","title":"ClimaDiagnostics.Schedules.AbstractSchedule","text":"AbstractSchedule\n\nAbstractSchedules are structs that behave like functions and are used for the purpose of defining a schedule to be used in ScheduledDiagnostics. They also may contain additional information.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.Schedules.short_name","page":"APIs","title":"ClimaDiagnostics.Schedules.short_name","text":"short_name(schedule)\n\nShort of name of the given schedule. Typically used in names of files/datasets.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.Schedules.long_name","page":"APIs","title":"ClimaDiagnostics.Schedules.long_name","text":"long_name(schedule)\n\nLong of name of the given schedule. Typically used in attributes.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.Schedules.DivisorSchedule","page":"APIs","title":"ClimaDiagnostics.Schedules.DivisorSchedule","text":"DivisorSchedule\n\nTrue when the iteration number is evenly divisible by a given number.\n\nThis is roughly equivalent to: \"run this call back every N steps\", with the difference that no initial offset is possible.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.Schedules.EveryStepSchedule","page":"APIs","title":"ClimaDiagnostics.Schedules.EveryStepSchedule","text":"EveryStepSchedule()\n\nReturn a schedule that executes at the end of every step.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.Schedules.EveryDtSchedule","page":"APIs","title":"ClimaDiagnostics.Schedules.EveryDtSchedule","text":"EveryDtSchedule\n\nTrue every time the current time is larger than the previous time this schedule was true + Dt.\n\nNote, this function performs no checks on whether the step is aligned with dt or not.\n\nnote: Statefulness\nThis struct is stateful. Do not reuse the same instance for multiple callbacks.\n\nnote: Initialization\nIf the current time is not zero at initialization (e.g., when resuming from a restart), set the keyword argument t_last to the current time of the simulation.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.Schedules.EveryCalendarDtSchedule","page":"APIs","title":"ClimaDiagnostics.Schedules.EveryCalendarDtSchedule","text":"EveryCalendarDtSchedule\n\nReturns true if dt has passed since the last time this schedule was true. dt here is a Dates.Period (e.g., Dates.Month(1)).\n\nnote: Statefulness\nThis struct is stateful. Do not reuse the same instance for multiple callbacks.\n\nnote: Initialization\nIf the current date differs from the start date at initialization (e.g., when resuming from a restart), set the keyword argument date_last to the current date of the simulation.\n\ncompat: ClimaDiagnostics 0.2.4\nThis schedule was introduced in version 0.2.4.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.Schedules.EveryCalendarDtSchedule-Tuple{Any, ClimaUtilities.TimeManager.ITime}","page":"APIs","title":"ClimaDiagnostics.Schedules.EveryCalendarDtSchedule","text":"EveryCalendarDtSchedule(dt, t::ITime)\n\nConstruct an EveryCalendarDtSchedule from dt and t, where dt is a period or an ITime and t is an ITime. The start date of the schedule is epoch(t), and the last date on which the schedule returns true is date(t).\n\n\n\n\n\n","category":"method"},{"location":"api/#ClimaDiagnostics.DiagnosticVariables.DiagnosticVariable","page":"APIs","title":"ClimaDiagnostics.DiagnosticVariables.DiagnosticVariable","text":"DiagnosticVariable(;\n    compute!,\n    short_name = \"\",\n    long_name = \"\",\n    standard_name = \"\",\n    units = \"\",\n    comments = \"\"\n)\n\nA recipe to compute a diagnostic variable from the state, along with some useful metadata.\n\nThe primary use for DiagnosticVariables is to be embedded in a ScheduledDiagnostic to compute diagnostics while the simulation is running.\n\nThe metadata is used exclusively by the output_writer in the ScheduledDiagnostic. It is responsibility of the output_writer to follow the conventions about the meaning of the metadata and their use.\n\nIn ClimaAtmos, we roughly follow the naming conventions listed in this file: https://airtable.com/appYNLuWqAgzLbhSq/shrKcLEdssxb8Yvcp/tblL7dJkC3vl5zQLb\n\ncompat: ClimaDiagnostics 0.2.13\nSupport for compute was introduced in version 0.2.13. Prior to this version, the in-place compute! had to be provided.\n\nKeyword arguments\n\ncompute!: Function that computes the diagnostic variable from the state, cache, and             time. In addition to these three arguments, compute! has to take four             arguments, the destination where to write the result of the computation.\ncompute: Function that computes the diagnostic variable from the state, cache, and            time and returns either a Field or an un-evaluated expression (e.g., with            LazyBroadcast.lazy).\nshort_name: Name used to identify the variable in the output files and in the file               names. Short but descriptive. ClimaAtmos follows the CMIP conventions and               the diagnostics are identified by the short name.\nlong_name: Name used to describe the variable in the output files.\nstandard_name: Standard name, as in                  http://cfconventions.org/Data/cf-standard-names/71/build/cf-standard-name-table.html\nunits: Physical units of the variable.\ncomments: More verbose explanation of what the variable is, or comments related to how             it is defined or computed.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.DiagnosticVariables.short_name","page":"APIs","title":"ClimaDiagnostics.DiagnosticVariables.short_name","text":"short_name(dv::DiagnosticVariable)\n\nReturn the short name associated to the given DiagnosticVariable.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.Schedules.long_name-Tuple{ClimaDiagnostics.DiagnosticVariables.DiagnosticVariable}","page":"APIs","title":"ClimaDiagnostics.Schedules.long_name","text":"long_name(dv::DiagnosticVariable)\n\nReturn the long name associated to the given DiagnosticVariable.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClimaDiagnostics.DiagnosticVariables.descriptive_short_name","page":"APIs","title":"ClimaDiagnostics.DiagnosticVariables.descriptive_short_name","text":"descriptive_short_name(variable::DiagnosticVariable,\n                       output_schedule_func,\n                       reduction_time_func,\n                       pre_output_hook!)\n\nReturn a compact, unique-ish, identifier generated from the given information. This function is useful for filenames and error messages.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.DiagnosticVariables.descriptive_long_name","page":"APIs","title":"ClimaDiagnostics.DiagnosticVariables.descriptive_long_name","text":"descriptive_long_name(variable::DiagnosticVariable,\n                      output_every,\n                      reduction_time_func,\n                      pre_output_hook!)\n\nReturn a verbose description of the given output variable.\n\nThis function is useful for attributes in output files.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.ScheduledDiagnostics.ScheduledDiagnostic","page":"APIs","title":"ClimaDiagnostics.ScheduledDiagnostics.ScheduledDiagnostic","text":"ScheduledDiagnostic\n\nConceptually, a ScheduledDiagnostics is a DiagnosticVariable we want to compute in a given simulation. For example, it could be the temperature averaged over a day. We can have multiple ScheduledDiagnostics for the same DiagnosticVariable (e.g., daily and monthly average temperatures).\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.ScheduledDiagnostics.output_short_name","page":"APIs","title":"ClimaDiagnostics.ScheduledDiagnostics.output_short_name","text":"output_short_name(sd::ScheduledDiagnostic)\n\nReturn the short name to use for output of the ScheduledDiagnostic sd.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.ScheduledDiagnostics.output_long_name","page":"APIs","title":"ClimaDiagnostics.ScheduledDiagnostics.output_long_name","text":"output_long_name(sd::ScheduledDiagnostic)\n\nReturn the long name to use for output of the ScheduledDiagnostic sd.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.AbstractWriter","page":"APIs","title":"ClimaDiagnostics.AbstractWriter","text":"AbstractWriter\n\nAn object that knows how to save some output.\n\nAbstractWriters have to provide one function, write_field!\n\nThe function has to have signature write_field!(writer::Writer, field, diagnostic, u, p, t)\n\nIt is up to the Writer to implement this.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.Writers.DictWriter","page":"APIs","title":"ClimaDiagnostics.Writers.DictWriter","text":"The DictWriter is a writer that does not write to disk, but to memory (in a dictionary).\n\nThis is particularly useful for testing and debugging. This is not type stable (the underlying dictionary does not know in advance what types might be used).\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.Writers.NetCDFWriter","page":"APIs","title":"ClimaDiagnostics.Writers.NetCDFWriter","text":"NetCDFWriter\n\nA struct to remap ClimaCore Fields to rectangular grids and save the output to NetCDF files.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.Writers.HDF5Writer","page":"APIs","title":"ClimaDiagnostics.Writers.HDF5Writer","text":"HDF5Writer(output_dir)\n\nSave a ScheduledDiagnostic to a HDF5 file inside the output_dir.\n\nnote: Note\nThis writer is not very efficient, but it is currently the only writer that can save ClimaCore.Fields. Please, get in touch if you need this capability.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClimaDiagnostics.Writers.interpolate_field!","page":"APIs","title":"ClimaDiagnostics.Writers.interpolate_field!","text":"interpolate_field!(writer::NetCDFWriter, field, diagnostic, u, p, t)\n\nPerform interpolation of field and save output in preallocated areas of writer.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.Writers.write_field!","page":"APIs","title":"ClimaDiagnostics.Writers.write_field!","text":"write_field!(writer::DictWriter, field, diagnostic, u, p, t)\n\nAdd an entry to the writer at time t for the current diagnostic with value field.\n\nDictWriter is backed by a dictionary. Most typically, the keys of this dictionary are either strings, the output_short_name of the diagnostic. If the output_short_name is not available, use the diagnostic itself. The values of this dictionary is another dictionary that maps the time t to the field at that value.\n\nDictWriter implements a basic read-only dictionary interface to access the times and values.\n\n\n\n\n\nwrite_field!(writer::HDF5Writer, field, diagnostic, u, p, t)\n\nSave a ScheduledDiagnostic to a HDF5 file inside the output_dir.\n\nThe name of the file is determined by the output_short_name of the output ScheduledDiagnostic. New files are created for each timestep.\n\nFields can be read back using the InputOutput module in ClimaCore.\n\n\n\n\n\nwrite_field!(writer::NetCDFWriter, field::Fields.Field, diagnostic, u, p, t)\n\nSave the resampled field produced by diagnostic as directed by the writer.\n\nOnly the root process does something here.\n\nNote: It assumes that the field is already resampled.\n\nThe target file is determined by output_short_name(diagnostic). If the target file already exists, append to it. If not, create a new file. If the file does not contain dimensions, they are added the first time something is written.\n\nTime handling:\n\nFor reduced diagnostics: timestamps are stored at the START of the reduction period, with time_bnds showing [start, end] of the period. For the first write, t=0 is assumed; for subsequent writes, the end of the previous period is used.\nFor instantaneous diagnostics: timestamps are stored at the current time, with timebnds showing [previoustime, current_time].\n\nAttributes are appended to the dataset:\n\nshort_name\nlong_name\nunits\ncomments\nstart_date\n\n\n\n\n\n","category":"function"},{"location":"api/#ClimaDiagnostics.Writers.default_num_points","page":"APIs","title":"ClimaDiagnostics.Writers.default_num_points","text":"default_num_points(space)\n\nReturn a tuple with number of points that are optimally suited to interpolate the given space.\n\n\"Optimally suited\" here means approximately the same as the number of points as the given space.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.close","page":"APIs","title":"Base.close","text":"close(writer::HDF5Writer)\n\nClose all the files open in writer. (Currently no-op.)\n\n\n\n\n\nclose(writer::NetCDFWriter)\n\nClose all the open files in writer.\n\n\n\n\n\n","category":"function"},{"location":"user_guide/#user_guide_header","page":"User guide","title":"What do I have to do to use ClimaDiagnostics?","text":"In this page, we describe the low level interface that ClimaDiagnostics offers to work with diagnostics. Most packages implement addition interface to streamline computing and outputting diagnostics, so you should first refer to the manual of your package of interest. Come back here if you want to go beyond what the package developers offer and unlock the full power of ClimaDiagnostics.\n\nThere are two fundamental objects in ClimaDiagnostics: the DiagnosticVariable, and the ScheduledDiagnostic.","category":"section"},{"location":"user_guide/#DiagnosticVariables","page":"User guide","title":"DiagnosticVariables","text":"A DiagnosticVariable is a recipe on how to compute something alongside with some metadata.\n\nFor example, a DiagnosticVariable might be the air temperature. In pseudocode, some of the information we might want to include attach to the air temperature are:\n\nshort_name: \"ta\"\nlong_name: \"Air Temperature\"\nunits: \"K\"\nhow_to_compute: state.ta\n...\n\nConceptually, a DiagnosticVariable is a variable we know how to compute from the state. We attach more information to it for documentation and to reference to it with its short name. DiagnosticVariables can exist irrespective of the existence of an actual simulation that is being run. Science packages are encouraged to define their set of pre-made DiagnosticVariables, for example, ClimaAtmos comes with several diagnostics already defined (in the ALL_DIAGNOSTICS dictionary).\n\nLet us see how we would define a DiagnosticVariable\n\nimport ClimaDiagnostics: DiagnosticVariable\n\nfunction compute_ta(state, cache, time)\n    return state.ta\nend\n\nvar = DiagnosticVariable(;\n    short_name = \"ta\",\n    long_name = \"Air Temperature\",\n    standard_name = \"air_temperature\",\n    comments = \"Measured assuming that the air is in quantum equilibrium with the metaverse\",\n    units = \"K\",\n    compute = compute_ta\n)\n\ncompute_ta is the key function here. It determines how the variable should be computed from the state, cache, and time of the simulation. Typically, these are packaged within an integrator object (e.g., state = integrator.u or integrator.Y).\n\ncompat: ClimaDiagnostics 0.2.13\nSupport for compute was introduced in version 0.2.13. Prior to this version, the in-place compute! had to be provided. In this case, compute has to take an extra argument, out. out is an area of memory managed by ClimaDiagnostics that is used to reduce the number of allocations needed when working with diagnostics. The first time the diagnostic is called, an area of memory is allocated and filled with the value (this is when out is nothing). All the subsequent times, the same space is overwritten, leading to much better performance. You should follow this pattern in all your diagnostics. This is left to developer to implement, so compute_ta would look likefunction compute_ta!(out, state, cache, time)\n    if isnothing(out)\n        return state.ta\n    else\n        out .= state.ta\n    end\nendIn general, we do not recommend implementing compute!, unless required for backward compatibility.\n\nWhen the expression is anything more complicated than just returning a Field, it is best to return an unevaluated expression represented by a Base.Broadcast.Broadcasted object (such as the ones produced with LazyBroadcast.jl). Consider the following example where we want to shift the temperature to Celsius:\n\nfunction compute_ta(state, cache, time)\n    return state.ta .- 273.15\nend\n\nThis compute function is inefficient because it allocates an entire Field before returning it. Instead, we can return just a recipe on how the diagnostic should be computed: Using LazyBroadcast.jl, the snippet above can be rewritten as\n\nimport LazyBroadcast: lazy\n\nfunction compute_ta(state, cache, time)\n    return lazy.(state.ta .- 273.15)\nend\n\nThe return value of compute_ta is a Base.Broadcast.Broadcasted object and ClimaDiagnostics knows how to handle it efficiently, avoiding the intermediate allocations.\n\nA DiagnosticVariable defines what a variable is and how to compute it, but does not specify when to compute/output it. For that, we need ScheduledDiagnostics.","category":"section"},{"location":"user_guide/#ScheduledDiagnostics","page":"User guide","title":"ScheduledDiagnostics","text":"A ScheduledDiagnostic is a DiagnosticVariable with attached a schedule on when it should be computed and output, as well as what reductions should be performed and how the file should be written.\n\nContinuing our example on ta. Suppose we want to compute the average of the air temperature over a month. We would package this in a ScheduledDiagnostic that knows that we want to compute the air temperature, and we want it averaged over a month.\n\nLet us examine what is in a ScheduledDiagnostic in more details:\n\nvariable, the DiagnosticVariable we want to compute.\ntwo schedule functions that determine when the variable should be computed and output (compute_schedule_func and output_schedule_func). We have two separate entries one for compute and one for output because we might want to control them separately. For example, we might want to take the average of something every 10 steps, and output it the average every 100 iterations. schedule functions are powerful, so there is an entire section dedicated to them below. compute_schedule_func and output_schedule_func are likely going to be the same unless there are temporal reductions.\nan output_writer, an object that knows what to do with the output. Examples of writers might be the DictWriter, which saves the output to a dictionary, or the NetCDFWriter, which saves the output to NetCDF files. A more complete description of the available writers is in Saving the diagnostics page.\noutput_short_name and output_long_name, two strings that specify the names that should be used for the output. Typically, output_short_name is used for file/key names, output_long_name is used for descriptive attributes. If none is provided, one is automatically generated by the output_short_name and output_long_name functions.\nreduction_time_func, a function that implements a temporal reduction. Discussed later. This is what you need to implement operations like arithmetic averages. A pre_output_hook! function can also be passed to do some basic normalization operations.\n\nNote that we can have multiple ScheduledDiagnostics for the same DiagnosticVariable (e.g., daily and monthly average temperatures).","category":"section"},{"location":"user_guide/#schedules_header","page":"User guide","title":"Schedules","text":"ScheduledDiagnostics contain two arguments compute_schedule_func and output_schedule_func which dictate when the variable should be computed and when it should be output. These objects have to be functions that take a single argument (the integrator) and return a boolean value.\n\nFor example, if we want to call a callback every even step, we could pass\n\nfunction compute_every_even(integrator)\n    return mod(integrator.step, 2) == 0\nend\n\nSchedules can be arbitrary. For example, we might want to compute something if the value of the variable var is greater than 100 anywhere. The relevant schedule for this would be\n\nfunction compute_if_larger_than100(integrator)\n    return maximum(integrator.u.var) > 100\nend\n\nStrictly speaking, schedules do not have to be functions, but callable objects. For example, the compute_every_even schedule we defined earlier could be written for a more general divisor\n\nstruct EveryDivisor\n    divisor::Int\nend\n\nfunction (schedule::EveryDivisor)(integrator)\n    return mod(integrator.step, schedule.divisor) == 0\nend\n\ncompute_every_even = EveryDivisor(2)\n\nThis gives schedules great flexibility because it allows them to contain a state that can be changed.\n\nClimaDiagnostics define an AbstractSchedule type to implement generic schedules following the pattern just illustrated. One of the main roles of AbstractSchedules is to have meaningful names that can be used in files/datasets/error messages, and so on. For this reason, Schedules in ClimaDiagnostics define methods for short_name and long_name.\n\nIf you define your own schedule, you are encouraged to define those methods too.\n\nLet us see a complete example of a new schedule that returns true when a variable is greater than a threshold.\n\nimport ClimaDiagnostics\n\nstruct ExceedThresholdSchedule <: ClimaDiagnostics.AbstractSchedule\n    var::Symbol\n    threshold::Float64\nend\n\nfunction (schedule::ExceedThresholdSchedule)(integrator)\n    return maximum(getproperty(integrator.u, schedule.var)) > schedule.threshold\nend\n\nfunction ClimaDiagnostics.Callback.short_name(schedule::ExceedThresholdSchedule)\n    return \"$(schedule.var)_more_than_$(schedule.threshold)\"\nend\n\nfunction ClimaDiagnostics.Callback.long_name(schedule::ExceedThresholdSchedule)\n    return \"when max($(schedule.var)) >= $(schedule.threshold)\"\nend\n\nNames are not too important, but they should be meaningful to you.\n\nClimaDiagnostics comes with some predefined schedules for common operations, such out every N timesteps, or every calendar period. Refer to the Schedules section below for more information on what is already implemented.\n\nnote: Note\nSchedules store some information about the last time they were called, so different Schedules have to be used and created for different purposes. You can use the deepcopy function to quickly create a new Schedule.","category":"section"},{"location":"user_guide/#Temporal-reductions","page":"User guide","title":"Temporal reductions","text":"It is often useful to compute aggregate data (e.g., monthly averages). In ClimaDiagnostics, this is implemented with through temporal reductions.\n\nLet us assume we want to compute the maximum of the air temperature within a month. To achieve this, we simply pass the max function to reduction_time_func and choose our window in the output_schedule_func.\n\nThe only temporal reductions allowed are ones defined by associative operations, that is, functions f so that f(a, b, c, d, ...) = f(a, f(b, f(c, f(d, ...)))) (such as the sum). The reason for this restriction comes from the fact that we do not store all the intermediate values (which would lead to large consumption of memory). Instead, we accumulate intermediate results. So, the only statistics that can be computed are the ones that can be computed by adding one element at the time.\n\nMore specifically, when a ScheduledDiagnostic is created with a reduction_time_func, ClimaDiagnostics allocates an extra area of space accumulated for the accumulated value. Every time compute_schedule_func is true, the DiagnosticVariable is computed and saved to out. Then, accumulated is updated with the return value of reduction_time_func(accumulated, out). When output_schedule_func is true, the accumulated value is written with the writer and the state reset to the neutral state.\n\nTo allow for greater flexibility, ClimaDiagnostics also provides the option to evaluate a function before the output is saved. This is the pre_output_hook! function that can be provided when defining a ScheduledDiagnostic. The signature for pre_output_hook! has to be pre_output_hook!(accumulated_value, counter), where counter is the number of times the diagnostic was called. Given this, the arithmetic average is obtained with a + time reduction and a pre_output_hook! = (acc, counter) -> acc .= acc ./ counter. Given that averages are very common operations, ClimaDiagnostics directly provides the pre_output_hook. So, to define an average, you can directly import and use ClimaDiagnostics.average_pre_output_hook!.\n\nThe following is a sketch of what happens at the end of each step for each ScheduledDiagnostic:\n\nif compute_schedule_func is true:\n    out = compute!\n    if reduction_time_func is not nothing:\n        accumulated_value = reduction_time_func(accumulated_value, out)\n        counter += 1\nif output_schedule_func is true:\n    pre_output_hook(accumulated_value, counter)\n    interpolate(accumulated_value)\n    dump(accumulated_value)\n    reset(accumulated_value)\n    reset(counter)","category":"section"},{"location":"developer_guide/#I-am-a-developer,-how-do-I-add-ClimaDiagnostics.jl-to-my-package?","page":"How to add ClimaDiagnostics to a package","title":"I am a developer, how do I add ClimaDiagnostics.jl to my package?","text":"This page provides additional documentation on abstractions to use ClimaDiagnostics. Before reading this page, make sure you are familiar with the terminology. You need to know what a DiagnosticVariable and a ScheduledDiagnostic are.\n\nThere are two components needed to add support for ClimaDiagnostics.jl in your package.\n\nA way to convert users' intentions to a list of ScheduledDiagnostic\nA call to IntegratorWithDiagnostics, if you have an integrator (if you do not have an integrator read the What if I do not have an integrator? section)","category":"section"},{"location":"developer_guide/#Step-2","page":"How to add ClimaDiagnostics to a package","title":"Step 2","text":"Let us assume that scheduled_diagnostics is the list of ScheduledDiagnostics obtained from step 1. (more on this later), and integrator a SciML integrator.\n\nAll we need to do to add diagnostics is\n\nimport ClimaDiagnostics: IntegratorWithDiagnostics\n\nintegrator = IntegratorWithDiagnostics(integrator, scheduled_diagnostics)\n\nCreating an IntegratorWithDiagnostics results in calling all the diagnostics once. Therefore, the compile and runtime of this function can be significant if you have a large number of diagnostics.\n\nYou can learn about what is happening under the hook in the Internals page.\n\nThis is pretty much all that you need to know about step 2.","category":"section"},{"location":"developer_guide/#What-if-I-do-not-have-an-integrator?","page":"How to add ClimaDiagnostics to a package","title":"What if I do not have an integrator?","text":"ClimaDiagnostics does not assume that you are working with an integrator object, so you can use it in your project even when you hold your simulation fields in other data structures. \n\nDiagnosticVariables in ClimaDiagnostics come with a compute! function with a specific signature compute!(out, state, cache, time). This is required because ClimaDiagnostics calls them by calling compute!(out, integrator.u, integrator.p, integrator.t). If you do not have an integrator, all you have to do is create a wrapper that exposes this interface.\n\nFor example, you could have fields, parameters, and time, and you could wrap them in a my_integrator = (; u = fields, p = parameters, t = time) and use the objects in the compute! function as you like. \n\nThe integrator-equivalent object is also used in Schedules. For time-dependent schedules, integrator.t is used. For step-dependent schedules (e.g., ClimaDiagnostics.Schedules.EveryStepSchedule), the step field is used. If you are using these schedules, do also add step to your my_integrator.\n\nIf you do not have an integrator, it is likely that you do not have a callback system either. In this case, you would have to manually call the ClimaDiagnostics.orchestrate_diagnostics at the end of each of your steps. orchestrate_diagnostics is the heart of ClimaDiagnostics: it runs all the calculations are saves the output. Usually, it is added as a callback called at the end of every step. If this is not possible, you should manually call it.\n\nIn this case, your interface would probably require you to manually construct the ClimaDiagnostics.DiagnosticsHandler\n\nsummary: Summary\nWrap your objects in my_integrator = (; u = fields, p = parameters, t = time, step = step)\nManually construct a ClimaDiagnostics.DiagnosticsHandler from your ClimaDiagnostics.ScheduledDiagnostic\nManually call a ClimaDiagnostics.orchestrate_diagnostics at the end of each step","category":"section"},{"location":"developer_guide/#Step-1","page":"How to add ClimaDiagnostics to a package","title":"Step 1","text":"Step 1 in the recipe to bring ClimaDiagnostics to your package strongly depends on you.\n\nIn this section, I will present a tower of interfaces that you can put in place to make it more convenient for your users. Keep in mind that each layer trades more convenience for less flexibility. So, as you set up your interfaces, I recommend you keep them exposed so that your users can access lower-level functions if they need to.","category":"section"},{"location":"developer_guide/#Level-0:-do-nothing","page":"How to add ClimaDiagnostics to a package","title":"Level 0: do nothing","text":"At the zero-th level, you let your users work directly with ClimaDiagnostics. This means that they will have to define their own DiagnosticVariables and ScheduledDiagnostics. This also requires that your simulation is executed as a julia script.\n\nIt is a good idea for your users to be aware of this possibility because it brings enormous power. ScheduledDiagnostics can be triggered on arbitrary conditions, and your users could be creative with that. For example, users might want to compute and output a variable var1 when they find that the maximum of variable var2 is greater than a threshold (e.g., for debugging).\n\nLet us see the simplest example to accomplish this\n\nimport ClimaDiagnostics: DiagnosticVariable, ScheduledDiagnostic\nimport ClimaDiagnostics.Writers: DictWriter\n\nmyvar = DiagnosticVariable(; compute = (u, p, t) -> u.var1)\n\nmyschedule = (integrator) -> maximum(integrator.u.var2) > 10.0\n\ndiag = ScheduledDiagnostic(variable = myvar,\n                           compute_schedule_func = myschedule,\n                           output_schedule_func = myschedule,\n                           output_writer = DictWriter())\n\nNow we can go to step 2 and 3 in the previous list and pass [diag] to the DiagnosticsHandler.\n\nPoint your users to the documentation of this package for them to learn how to use it in its full power.","category":"section"},{"location":"developer_guide/#Level-1:-provide-a-database-of-DiagnosticVariables","page":"How to add ClimaDiagnostics to a package","title":"Level 1: provide a database of DiagnosticVariables","text":"As a package developer, you know that there is a large collection of variables that several users will be interested in. For example, if you are running an atmospheric simulation, your users will want to be able to look at the air temperature. For this reason, it is a very good (and user-friendly) idea to provide a collection of DiagnosticVariables ready to be used. In this section, I sketch how you could go about and implement this.\n\nYour DiagnosticVariables database can be represented as a dictionary ALL_DIAGNOSTICS indexed over the short name of the variable. Then, you could provide adders and accessors.\n\nThis might look like the following:\n\nmodule Diagnostics\nimport ClimaDiagnostics: DiagnosticVariable\n\nconst ALL_DIAGNOSTICS = Dict{String, DiagnosticVariable}()\n\n\"\"\"\n\n    add_diagnostic_variable!(; short_name,\n                               long_name,\n                               standard_name,\n                               units,\n                               description,\n                               compute)\n\n\nAdd a new variable to the `ALL_DIAGNOSTICS` dictionary (this function mutates the state of\n`ALL_DIAGNOSTICS`).\n\nIf possible, please follow the naming scheme outline in\nhttps://airtable.com/appYNLuWqAgzLbhSq/shrKcLEdssxb8Yvcp/tblL7dJkC3vl5zQLb\n\nKeyword arguments\n=================\n\n- `short_name`: Name used to identify the variable in the output files and in the file\n                names. Short but descriptive. Diagnostics are identified by the short name.\n\n- `long_name`: Name used to identify the variable in the output files.\n\n- `standard_name`: Standard name, as in\n                   http://cfconventions.org/Data/cf-standard-names/71/build/cf-standard-name-table.html\n\n- `units`: Physical units of the variable.\n\n- `comments`: More verbose explanation of what the variable is, or comments related to how\n              it is defined or computed.\n\n- `compute`: Function that computes the diagnostic variable from the state, cache, and time. The function\n             should return a `Field` or a `Base.Broadcast.Broadcasted` expression. It should not allocate\n             new `Field`: if you find yourself using a dot, that is a good indication you should be using\n             `lazy`.\n\"\"\"\nfunction add_diagnostic_variable!(;\n    short_name,\n    long_name,\n    standard_name = \"\",\n    units,\n    comments = \"\",\n    compute,\n)\n    haskey(ALL_DIAGNOSTICS, short_name) && @warn(\n        \"overwriting diagnostic `$short_name` entry containing fields\\n\" *\n        \"$(map(\n            field -> \"$(getfield(ALL_DIAGNOSTICS[short_name], field))\",\n            # We cannot really compare functions...\n            filter(field -> !(field in (:compute!, :compute)), fieldnames(DiagnosticVariable)),\n        ))\"\n    )\n\n    ALL_DIAGNOSTICS[short_name] = DiagnosticVariable(;\n        short_name,\n        long_name,\n        standard_name,\n        units,\n        comments,\n        compute,\n    )\n\n\"\"\"\n    get_diagnostic_variable!(short_name)\n\nReturn a `DiagnosticVariable` from its `short_name`, if it exists.\n\"\"\"\nfunction get_diagnostic_variable(short_name)\n    haskey(ALL_DIAGNOSTICS, short_name) ||\n        error(\"diagnostic $short_name does not exist\")\n\n    return ALL_DIAGNOSTICS[short_name]\nend\n\nend\n\nOf course, you should have the fields and comments that are relevant to your package.\n\nNext, as a developer, you will use add_diagnostic_variable! to populate your database. You can also expose your users to this function so that they can extend their personal database in their simulations.\n\nA simple example of a new variable might look like\n\n###\n# Density (3d)\n###\nadd_diagnostic_variable!(\n    short_name = \"rhoa\",\n    long_name = \"Air Density\",\n    standard_name = \"air_density\",\n    units = \"kg m^-3\",\n    compute = (state, cache, time) -> state.c.Ï,\n)\n\nWhen writing compute functions, make them lazy with LazyBroadcast.jl to improve performance and avoid intermediate allocations. To do that, add LazyBroadcast to your dependencies and import lazy. A slight variation of the previous example would look like\n\n###\n# Density (3d)\n###\nadd_diagnostic_variable!(\n    short_name = \"rhoa\",\n    long_name = \"Air Density\",\n    standard_name = \"air_density\",\n    units = \"kg m^-3\",\n    compute = (state, cache, time) -> lazy.(1000 .* state.c.Ï),\n)\n\nWhere we added the 1000 to simulate a more complex expression. If you didn't have lazy, the diagnostic would allocate an intermediate Field, severly hurting performance.\n\nIt is a good idea to put safeguards in place to ensure that your users will not be allowed to call diagnostics that do not make sense for the simulation they are running. If your package has a notion of Model that is stored in p, you can dispatch over that and return an error. A simple example might be\n\n###\n# Specific Humidity\n###\ncompute_hus(state, cache, time) =\n    compute_hus(state, cache, time, cache.atmos.moisture_model)\n\ncompute_hus(state, cache, time) =\n    compute_hus!(state, cache, time, cache.model.moisture_model)\ncompute_hus(_, _, _, model::T) where {T} =\n    error(\"Cannot compute hus with $model\")\n\nfunction compute_hus(\n    state,\n    cache,\n    time,\n    moisture_model::T,\n) where {T <: Union{EquilMoistModel, NonEquilMoistModel}}\n    return lazy.(state.c.Ïq_tot ./ state.c.Ï)\nend\n\nadd_diagnostic_variable!(\n    short_name = \"hus\",\n    long_name = \"Specific Humidity\",\n    standard_name = \"specific_humidity\",\n    units = \"kg kg^-1\",\n    comments = \"Mass of all water phases per mass of air\",\n    compute = compute_hus,\n)\n\nThis relies on dispatching over moisture_model. If model is not in Union{EquilMoistModel, NonEquilMoistModel}, the code returns an informative error.\n\nIf you provide a database, users can create their ScheduledDiagnostics directly from the DiagnosticVariables you provided.\n\nFor instance to output the specific humidity every 5 iterations:\n\nimport ClimaDiagnostics: ScheduledDiagnostic\nimport ClimaDiagnostics.Callbacks: DivisorSchedule\nimport ClimaDiagnostics.Writers: DictWriter\n\ndiag = ScheduledDiagnostic(variable = get_diagnostic_variable!(\"hus\"),\n                           output_schedule_func = DivisorSchedule(5),\n                           output_writer = DictWriter())\n\nAlongside with providing the DiagnosticVariables, you can also provide convenience functions for standard operations.\n\nFor example, you could provide\n\nusing ClimaDiagnostics.Callbacks: EveryStepSchedule, EveryDtSchedule\n\nfunction monthly_average(FT, short_name; output_writer)\n    period = 30 * 24 * 60 * 60 * one(FT)\n    return ScheduledDiagnostic(\n            variable = get_diagnostic_variable(short_name),\n            compute_schedule_func = EveryStepSchedule(),\n            output_schedule_func = EveryDtSchedule(period),\n            reduction_time_func = (+),\n            output_writer = output_writer,\n            pre_output_hook! = average_pre_output_hook!,\n        )\nend\n\nAllowing users to just call monthly_average(Float32, \"hus\", writer).\n\nNote: ClimaDiagnostics will probably provided these schedules natively at some point in the future.","category":"section"},{"location":"developer_guide/#Level-2:-Provide-higher-level-interfaces-(e.g.,-YAML)","page":"How to add ClimaDiagnostics to a package","title":"Level 2: Provide higher-level interfaces (e.g., YAML)","text":"Finally, you can set in place that parses user input (e.g., from command line or text files) into ScheduledDiagnostics using the short names in your database. Of course, this interface will be limited to what you expose.\n\nFor example, a simple parser that allow users to specify ScheduledDiagnostics by their short name, accumulation/output period, and their writer might look like the following:\n\nimport ClimaDiagnostics: average_pre_output_hook!, HDF5Writer, NetCDFWriter, ScheduledDiagnostic\n\nfunction parse_yaml(parsed_args, source_space)\n    # We either get the diagnostics section in the YAML file, or we return an empty list\n    # (which will result in an empty list being created by the map below)\n    yaml_diagnostics = get(parsed_args, \"diagnostics\", [])\n\n    # ALLOWED_REDUCTIONS is the collection of reductions we support. The keys are the\n    # strings that have to be provided in the YAML file. The values are tuples with the\n    # function that has to be passed to reduction_time_func and the one that has to passed\n    # to pre_output_hook!\n\n    # We make \"nothing\" a string so that we can accept also the word \"nothing\", in addition\n    # to the absence of the value\n    #\n    # NOTE: Everything has to be lowercase in ALLOWED_REDUCTIONS (so that we can match\n    # \"max\" and \"Max\")\n    ALLOWED_REDUCTIONS = Dict(\n        \"nothing\" => (nothing, nothing), # nothing is: just dump the variable\n        \"max\" => (max, nothing),\n        \"min\" => (min, nothing),\n        \"average\" => ((+), average_pre_output_hook!),\n    )\n\n    output_dir = parsed_args.output_dir\n\n    hdf5_writer = HDF5Writer(output_dir)\n    netcdf_writer = CAD.NetCDFWriter(\n        source_space,\n        output_dir,\n    )\n    writers = (hdf5_writer, netcdf_writer)\n\n    # The default writer is HDF5\n    ALLOWED_WRITERS = Dict(\n        \"nothing\" => netcdf_writer,\n        \"h5\" => hdf5_writer,\n        \"hdf5\" => hdf5_writer,\n        \"nc\" => netcdf_writer,\n        \"netcdf\" => netcdf_writer,\n    )\n\n    diagnostics_ragged = map(yaml_diagnostics) do yaml_diag\n        short_names = yaml_diag[\"short_name\"]\n        output_name = get(yaml_diag, \"output_name\", nothing)\n\n        map(short_names) do short_name\n            # Return \"nothing\" if \"reduction_time\" is not in the YAML block\n            #\n            # We also normalize everything to lowercase, so that can accept \"max\" but\n            # also \"Max\"\n            reduction_time_yaml =\n                lowercase(get(yaml_diag, \"reduction_time\", \"nothing\"))\n\n            if !haskey(ALLOWED_REDUCTIONS, reduction_time_yaml)\n                error(\"reduction $reduction_time_yaml not implemented\")\n            else\n                reduction_time_func, pre_output_hook! =\n                    ALLOWED_REDUCTIONS[reduction_time_yaml]\n            end\n\n            writer_ext = lowercase(get(yaml_diag, \"writer\", \"nothing\"))\n\n            if !haskey(ALLOWED_WRITERS, writer_ext)\n                error(\"writer $writer_ext not implemented\")\n            else\n                writer = ALLOWED_WRITERS[writer_ext]\n            end\n\n            haskey(yaml_diag, \"period\") ||\n                error(\"period keyword required for diagnostics\")\n\n            period_seconds = FT(time_to_seconds(yaml_diag[\"period\"]))\n\n            if isnothing(reduction_time_func)\n                compute_every = CAD.EveryDtSchedule(period_seconds)\n            else\n                compute_every = CAD.EveryStepSchedule()\n            end\n\n            ScheduledDiagnostic(\n                variable = get_diagnostic_variable(short_name),\n                output_schedule_func = CAD.EveryDtSchedule(period_seconds),\n                compute_schedule_func = compute_every,\n                reduction_time_func = reduction_time_func,\n                pre_output_hook! = pre_output_hook!,\n                output_writer = writer,\n            )\n        end\n    end\n\n    # Flatten the array of arrays of diagnostics\n    diagnostics = vcat(diagnostics_ragged...)\nend\n\nThis will be controlled by YAML blocks like\n\ndiagnostics:\n    - short_name: [\"ta\", \"va\"]\n      period: 60s\n      writer: nc\n    - short_name: [\"ua\"]\n      period: 1200s\n      reduction_time: \"average\"\n\nIt is typically a good idea to add the default diagnostics to the set of YAML-specified ones.","category":"section"},{"location":"#ClimaDiagnostics.jl","page":"Overview","title":"ClimaDiagnostics.jl","text":"ClimaDiagnostics.jl is a module that adds diagnostics to your CliMA simulations. Diagnostics are variables that are computed from your state when specific conditions are met (typically at set intervals of time) throughout the run and typically saved to disk.\n\nClimaDiagnostics.jl provides the infrastructure to schedule, compute, reduce, and output such variables.\n\nIf you are a user of a package that is already using ClimaDiagnostics.jl, you can jump to the User guide page.\n\nIf you are a developer interested in adding support for ClimaDiagnostics.jl in your package or learning about the internal design of this package, please read the Developer guide page.","category":"section"},{"location":"#Features","page":"Overview","title":"Features","text":"Define diagnostics as function of the integrator state and the cache;\nAccumulate diagnostics over period of times with associative binary temporal reductions (eg, averages);\nWork with calendar dates (eg, monthly averages);\nAllow users to define arbitrary new diagnostics;\nTrigger diagnostics on arbitrary conditions;\nSave output to HDF5 or NetCDF files, or a dictionary in memory;\nWork with lazy expressions (such as the ones produced by LazyBroadcast.jl).","category":"section"},{"location":"internals/#internals_header","page":"Internals","title":"Some notes about the internals of ClimaDiagnostics","text":"There are multiple moving parts to this package. In this page, we provide some notes about the internal design. This page also aims at clarifying the whys, i.e., explaining why things are the way they are. Learning about that might help you extend this package further.","category":"section"},{"location":"internals/#Schedules","page":"Internals","title":"Schedules","text":"Diagnostics are computed with a callback that is called at the end of each step. The centerpiece of is the orchestrate_diagnostics function, a master callback that is unconditionally executed at the end of each step. orchestrate_diagnostics loops over each registered diagnostic, computing and output those for which their trigger condition is met. Conditions are specified with schedule functions, function that take the integrator as single argument and return a boolean value that determines whether the callback should be executed or note. Most often, schedules_func are not simple functions, but callable objects (subtypes of AbstractSchedule). There are two reasons for this:\n\nMost realistic schedules need to hold additional data (e.g., the last time the function was called)\nWe want to attach names to use in the output\n\nMost of the details regarding schedules are described in the user guide. An internal detail that is not there is related to names. We define a method for show for AbstractSchedules. This method calls the short_name function.\n\nBase.show(io::IO, schedule::AbstractSchedule) =  print(io, short_name(schedule))\n\nThis allows us to set names of ScheduledDiagnostics with \"$schedule_func\" in both the case schedule_func is a normal function, or an AbstractSchedule.","category":"section"},{"location":"internals/#Accumulation","page":"Internals","title":"Accumulation","text":"Several diagnostics require performing reductions, such as taking the maximum or the average. Since it is not feasible to store all the lists of all the intermediate values, we aggregate the results in specific storage areas (e.g., we take max(max(max(max(t1, t2), t3), t4), t5) instead of max(t1, t2, t3, t4, t5) In this, it is convenient to preallocate the space where we want to accumulate the intermediate.\n\nAccumulation is accomplished by the accumulate! function. All this function does is applying the binary reduction_time_func to the previous accumulated value and the newly computed one and store the output to the accumulator.\n\nAfter an accumulated variable is output, the accumulator is reset to its natural state. This is achieved with the reset_accumulator! function. However, we have to fill the space with something that does not affect the reduction. This, by definition, is the identity of the operation. The identity of the operation + is 0 because x + 0 = x for every x.\n\nWe have to know the identity for every operation we want to support. Of course, users are welcome to define their own by adding new methods to identityofreduction.\n\nFor instance, to define the identity of the reduction -, one would write\n\nfunction ClimaDiagnostics.Diagnostics.identity_of_reduction(::typeof(-))\n    return 0\nend\n\n(Or add this to the reduction_identities.jl file.)","category":"section"},{"location":"internals/#On-the-design-of-the-DiagnosticsHandler","page":"Internals","title":"On the design of the DiagnosticsHandler","text":"There are two possible choices for accumulation of variables: each scheduled diagnostic can carry its accumulator and counters, or all the accumulators and counters are managed by a single central handler. ClimaDiagnostics implements this second approach. The author of this package has not decided whether this is a good idea or not. On one side, this allows us to have a concretely typed and well defined DiagnosticsHandler struct. On the other side, it forces us to initialize all the diagnostics at the very beginning of the simulation (this can also be a positive side, because it allows us to compile all the diagnostics at once). It might be worth exploring the alternative design where the ScheduledDiagnostics get their storage space the first time they are called.\n\nGiven this restriction, the main entry point for ClimaDiagnostics is the IntegratorWithDiagnostics function. This function is a little dissatisfying because it creates a new integrator obtained by copying all the fields of the old one and adding the diagnostics (with Accessors).","category":"section"},{"location":"internals/#Orchestrate-diagnostics","page":"Internals","title":"Orchestrate diagnostics","text":"One of the design goals for orchestrate_diagnostics is to keep all the broadcasted expression in the same function scope. This opens a path to optimize the number of GPU kernel launches. ","category":"section"}]
}
